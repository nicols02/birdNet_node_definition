OVERVIEW OF METHODS USED TO EXTRACT DATA FOR NETWORK MODELLING

This document describes the methods and assumptions used to extract data from eBird for migratory network modelling.

My output files are stored in:
./Outputs
Code to extract the data is stored in:
./R_scripts

#Key files#
-----------------------------------
Data files:
./eBird sightings data/far eastern curlew/ebd_faecur_relJun-2020/ebd_faecur_relJun-2020.txt
./eBird sightings data/ebd_sampling_relJun-2020/ebd_sampling_relJun-2020.txt
./Outputs/eastern_curlew_all_eBird2020.Rds (large file; generated by getData_curlew.R)
EAA_ID_sites.csv
far eastern curlew_IBAs.csv

R scripts:
getData_curlew.R
format_weekly_data.R


#Approach#
-----------------------------------
The approach is based largely on the migratory networks in Iwamura et al (2013). The aim is to reproduce the observed data for these networks 
from eBird. This requires us to associate location data to the qualitative regions used by experts in Iwamura's analysis, so there are a lot of decisions that need to be made.


Firstly, data was extracted from eBird using the 'auk' package. I have only extracted a single species (FE curlew). 
To begin, I downloaded the a custom request for eastern curlew from the eBird basic dataset and filtered it, following the instructions here: https://cran.r-project.org/web/packages/auk/vignettes/auk.html. 
Because this filtering process takes ages, it's done in a separate script, called getData_curlew.R. 
During this process I filter by country and by removing any data from the contiguous USA (i.e. all except Alaska), and by removing all data from western Russia (anything west of the 80th parallel). We do this extra filter to reduce the size of the zero-filled dataset, otherwise the script returns all global bird records. 
 The output of the script is called "eastern_curlew_all_eBird.Rds".

This extraction step is slow-- there are likely to be many ways to improve it.
The full list of columns maintained in the output Rds is (check auk for definitions of column names):

	c("checklist_id", "country", "country_code", "iba_code","state", "state_code","locality_id","locality_type", "latitude", "longitude", "observation_date", "sampling_event_identifier", "time_observations_started", "duration_minutes", "effort_distance_km", "effort_area_ha", "number_observers", "scientific_name", "observation_count", "species_observed", "protocol_type")

The 'format_weekly_data.R' script is used to manually create regional nodes that roughly match Iwamura's flyway network models. 
The script uses a csv of the locations of all the IBAs in the EAAF to aid us to define regions. 
All IBA information that I used is  (manually!) extracted from "Bamford, Watkins, Bancroft, Tischler, Wahl (2008) Migratory Shorebirds of the East
Asian-Australasian Flyway: Population estimates and internationally important sites. Wetlands International-- Oceania. Canberra Australia"
My list of IBAs is stored in 'EAA_ID_sites.csv'.
The list of IBAs (with locations) is clipped to the species of interest by merging with a list of IBAs relevant to the species: 'far eastern curlew_IBAs.csv'
Once we can see the locations of the IBAs, we need to manually select the boundaries of the regions in Iwamura's migratory networks.
This is currently done by drawing regions as polygons on the map based on the rough location of the region and trying to capture
all of the IBAs for the species within my regions (ensuring that most of the population is represented by the model). Logic behind the boundaries is contained in supporting information S1.
This step is also an opportunity to review Iwamura's network models for each species. We can ask other questions such as:
	1) should we add some new nodes to better represent the eBird count data? 
	2) are there alternative hypotheses that we want to investigate that wouldn't be captured by the current networks? (e.g. do we want to know if some curlews use a different flight path, such as staging in Taiwan or passing over the Phillipines?)
	
The 'format_weekly_data.R' script is then used to assign the count data to the regional nodes defined by comparison with the Iwamura nodes and IBAs. The script maps all checklists, performs some additonal filtering (including subsampling to reduce spatial bias in the checklists), and clips the
eBird dataset to assign count data to locations and regions.
After defining the regions, we clip the eBird count data to the regional extent. We also clip to only include recent data (I chose since 1980, but we
can decide together the best start date to choose). We remove all locations where the birds have never been sighted (e.g. zero counts at sites away from the coast which are likely to be outside the
species range, e.g. western Chinese sites are unlikely to be used by shorebirds).
We also pull out some summary data, such as how many uncounted birds aren't picked up by our classification into regions.
We then extract and plot the following data sets:
1) a total count for the region in each week;
2) total number of lists for the region in each week;
3) the average count per list within the region in each week;
We will use the weekly count data generated by this script to fit the "observed" average count of birds within the region as the basis to estimate the strength of 
connections between regional nodes. The goal is to learn the proportion of birds flying between regions to better inform conservation and cooperation between flyway countries.
A key assumption is that averaging over all years, all lists, and across all the sites in the region will help to reduce observer bias and detection issues (note that I will include a site-based detection probability estimate in my model).

 

